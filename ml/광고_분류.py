# -*- coding: utf-8 -*-
"""광고 분류.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AayjzawRvQaaCsgCAT4DpOE8CcrlVrb0
"""

!pip install PyMySQL

import pymysql
import pandas as pd
import datetime

blogdb = pymysql.connect(host='blogdb.cm2yxwfja9ii.ap-northeast-2.rds.amazonaws.com',
                      user='admin',
                      password='',
                      database='blogdb',
                      charset='utf8',
                      port=3306)

cursor =blogdb.cursor(pymysql.cursors.DictCursor)

# 데이터불러오기
query = "SELECT * FROM post_data where  map=1 And ad_status = 'NEED-TO-PROCESS' and res_id<157"
cursor.execute(query)

df = pd.read_sql_query(query, blogdb)

df



"""## images에서 마지막 2개 url 뽑아오기"""

df.images[0]

# 이미지 URL들을 개별로 분리하여 리스트로 저장
image1 =df.images[0].strip().split('\n')

search_s = "store"
sti=[item for item in image1 if search_s in item]
no_sti = [item for item in image1 if search_s not in item]
sti[-1]
no_sti[-1]

image1[0]

# 마지막 2개의 이미지 URL 뽑아오기
last_two_image_urls = image1[-2:]

# 결과 출력
for idx, image_url in enumerate(last_two_image_urls, start=len(image1)-1):
    print(f"Image {idx+1}: {image1}")

# images 컬럼의 URL들을 분리하여 리스트로 만들기
df['image_urls'] = df['images'].apply(lambda x: x.split('\n'))

# "store"를 포함하는 URL 중 마지막 하나와 포함되지 않은 URL 중 마지막 하나 뽑아오기
def get_last_urls(urls):
    store_urls = [url for url in urls if 'store' in url]
    non_store_urls = [url for url in urls if 'store' not in url]

    last_urls = []
    if store_urls:
        last_urls.append(store_urls[-1])
    if non_store_urls:
        last_urls.append(non_store_urls[-1])

    return last_urls

df['last_urls'] = df['image_urls'].apply(get_last_urls)

# 새로운 데이터프레임 생성
new_data = []
for _, row in df.iterrows():
    if len(row['last_urls']) == 2:
        new_data.append({'id': row['id'], 'url': ', '.join(row['last_urls'])})
    else:
        new_data.append({'id': row['id'], 'url': row['last_urls'][0]})

new_df = pd.DataFrame(new_data)

new_df

new_df.url[3]

"""## 이미지ocr"""

# -*- coding: utf-8 -*-
"""230818 vision ai .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w86hzJtHyHFJf_jq7NByV7mcxBxqH984
"""

!pip install google-cloud-vision

from google.cloud import vision
import io
import os
import requests
import re

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/MyDrive/Colab Notebooks/project1-393401-6e3fff67ffb5.json'

def str_filter(text):
    html_spch = ['&quot;','&amp;','&lt;','&gt;','&apos;',
             '&nbsp;','&iexcl;','&cent;','&pound;',
             '&curren;','&yen;','&brvbar;','&sect;',
             '&uml;','&copy;','&ordf;','&laquo;','&not;',
             '&shy;','&reg;','&macr;','&deg;','&plusmn;',
             '&sup2;','&sup3;','&acute;','&micro;','&para;',
             '&middot;','&cedil;','&sup1;','&ordm;','&raquo;',
             '&frac14;','&frac12;','&frac34;','&iquest;']
    html_tag = ['<b>','\n','</b>','<b/>','<a>','</a>','<a/>',
            '<br>','</br>','<br/>','<p>','</p>','<p/>',
            '<strong>','</strong>','<strong/>']
    html_spch_tag = html_spch + html_tag
    or_exp = '|'.join(html_spch_tag)
    text = re.sub(or_exp," ",text)
    text1= re.sub(r'[^\w\s]',' ',text)
    text2= re.sub(r"^\s+|\ㄴ+$","",text1) # 양측 공백 제거
    return text2

def image_text(img_path):
    # Initialize the client
    client = vision.ImageAnnotatorClient()

    # Load the image
    image_link = img_path

    image_response = requests.get(image_link)
    image_content = image_response.content
    image = vision.Image(content=image_content)

    # Perform text detection
    response = client.text_detection(image=image)
    texts = response.text_annotations

    if texts:
        img_text = str(texts[0].description)
    else:
        img_text = None

    return img_text

image_text('https://storep-phinf.pstatic.net/ogq_5b7813b4be670/original_3.png?type=p100_100')



# -*- coding: utf-8 -*-
"""230818 vision ai .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w86hzJtHyHFJf_jq7NByV7mcxBxqH984
"""

!pip install google-cloud-vision

from google.cloud import vision
import io
import os
import requests
import re
import base64

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/MyDrive/Colab Notebooks/project1-393401-6e3fff67ffb5.json'

def str_filter(text):
    html_spch = ['&quot;','&amp;','&lt;','&gt;','&apos;',
             '&nbsp;','&iexcl;','&cent;','&pound;',
             '&curren;','&yen;','&brvbar;','&sect;',
             '&uml;','&copy;','&ordf;','&laquo;','&not;',
             '&shy;','&reg;','&macr;','&deg;','&plusmn;',
             '&sup2;','&sup3;','&acute;','&micro;','&para;',
             '&middot;','&cedil;','&sup1;','&ordm;','&raquo;',
             '&frac14;','&frac12;','&frac34;','&iquest;']
    html_tag = ['<b>','\n','</b>','<b/>','<a>','</a>','<a/>',
            '<br>','</br>','<br/>','<p>','</p>','<p/>',
            '<strong>','</strong>','<strong/>']
    html_spch_tag = html_spch + html_tag
    or_exp = '|'.join(html_spch_tag)
    text = re.sub(or_exp," ",text)
    text1= re.sub(r'[^\w\s]',' ',text)
    text2= re.sub(r"^\s+|\ㄴ+$","",text1) # 양측 공백 제거
    return text2


def image_text1(img_path):
    # Initialize the client
    client = vision.ImageAnnotatorClient()

    # Load the image
    image_link = img_path

    image_response = requests.get(image_link)
    image_content = image_response.content

    # 이미지 데이터를 Base64로 인코딩
    base64_encoded_image = base64.b64encode(image_content).decode('utf-8')
    image = vision.Image(content=base64_encoded_image)

    # Perform text detection
    response = client.text_detection(image=image)
    texts = response.text_annotations

    if texts:
       img_text1 = str(texts[0].description)
    else:
       img_text1 = None

    return img_text1

image_text1('https://storep-phinf.pstatic.net/ogq_5b7813b4be670/original_3.png?type=p100_100')

# new_df의 url 열에 저장된 이미지 URL을 분리하여 리스트로 변환
url_lists = new_df['url'].str.split(',')

# 각 URL에 대해 image_text 함수를 적용하여 OCR 결과를 가져와 리스트에 저장
ocr_texts = []
for url_list in url_lists:
    ocr_result = []
    for url in url_list:
        try:
            ocr_result.append(image_text1(url.strip()))
        except Exception as e:
            print(f"Error processing URL: {url.strip()}\nError message: {e}")
    ocr_texts.append(', '.join(filter(None, ocr_result)))

# ocr_texts 리스트를 new_df의 ocr_text 열에 저장
new_df['ocr_text'] = ocr_texts

"""## 광고 분류"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
from sklearn.svm import SVC
import joblib

# 데이터 불러오기
data = pd.read_csv('adocr.csv',encoding='euc-kr')
data = data.drop('Unnamed: 2', axis=1)

# 텍스트 데이터 토큰화 및 벡터화
vectorizer = TfidfVectorizer()
x = vectorizer.fit_transform(data['content'])

# 훈련 데이터와 테스트 데이터 분리
x_train, x_test, y_train, y_test = train_test_split(x, data['label'], test_size=0.2, random_state=42)


# SVM 모델 생성 및 훈련
svm = SVC()
svm.fit(x_train, y_train)

# 모델 평가
y_pred = svm.predict(x_test)
print(classification_report(y_test, y_pred))

# 예측하고 싶은 텍스트 데이터 토큰화 및 벡터화
x_new = vectorizer.transform(['NO광고NO협찬'])

# 저장된 모델로 예측 수행
predicted_label = loaded_model.predict(x_new)
print('Predicted Label:', predicted_label)





