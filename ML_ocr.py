# -*- coding: utf-8 -*-
"""스티커 머신러닝.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C_VPURqwhz9IaTprqIZSrNHLAupGP1P1
"""

import pandas as pd

df = pd.read_csv('adocr.csv',encoding='euc-kr')
df = df.drop('Unnamed: 2', axis=1)

df.isnull().sum()

"""## 텍스트 벡터화"""

from sklearn.feature_extraction.text import TfidfVectorizer

# TfidfVectorizer 객체 생성
vectorizer = TfidfVectorizer()

# 텍스트 데이터 토큰화 및 벡터화
x_train_vectorized = vectorizer.fit_transform(x_train['content'])

# 벡터화된 결과를 DataFrame으로 변환
import pandas as pd
vec_df = pd.DataFrame(x_train_vectorized.toarray(), columns=vectorizer.get_feature_names_out())

# 결과 확인
print(vec_df)

"""## KNN알고리즘으로 분류"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

# 데이터 불러오기
data = pd.read_csv('adocr.csv',encoding='euc-kr')
data = data.drop('Unnamed: 2', axis=1)

# 텍스트 데이터 토큰화 및 벡터화
vectorizer = TfidfVectorizer()
x = vectorizer.fit_transform(data['content'])

# 훈련 데이터와 테스트 데이터 분리
x_train, x_test, y_train, y_test = train_test_split(x, data['label'], test_size=0.2, random_state=42)

# KNN 모델 생성 및 훈련
k = 5  # K 값 설정
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(x_train, y_train)

# 모델 평가
y_pred = knn.predict(x_test)
print(classification_report(y_test, y_pred))

"""## 서포트 벡터 머신으로 분류"""

from sklearn.svm import SVC

# SVM 모델 생성 및 훈련
svm = SVC()
svm.fit(x_train, y_train)

# 모델 평가
y_pred = svm.predict(x_test)
print(classification_report(y_test, y_pred))

"""## 예제 넣어서 확인"""

import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

# 데이터 불러오기
data = pd.read_csv('adocr.csv',encoding='euc-kr')
data = data.drop('Unnamed: 2', axis=1)

# 텍스트 데이터 토큰화 및 벡터화
vectorizer = TfidfVectorizer()
x = vectorizer.fit_transform(data['content'])

# 훈련 데이터와 테스트 데이터 분리 (학습된 벡터라이저 사용)
x_train, x_test, y_train, y_test = train_test_split(x, data['label'], test_size=0.2, random_state=42)

# SVM 모델 생성 및 훈련
svm = SVC()
svm.fit(x_train, y_train)

# 학습된 모델 저장
joblib.dump(svm, 'svm_model.pkl')  # 모델 저장 파일 경로에 맞게 수정

# 저장된 모델 불러오기
loaded_model = joblib.load('svm_model.pkl')

# 예측하고 싶은 텍스트 데이터 토큰화 및 벡터화
x_new = vectorizer.transform(['NO광고NO협찬'])

# 저장된 모델로 예측 수행
predicted_label = loaded_model.predict(x_new)
print('Predicted Label:', predicted_label)